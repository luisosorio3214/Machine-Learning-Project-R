---
title: "Airline Passenger Satisfaction"
output: 
  html_document: 
  pdf_document:
    latex_engine: xelatex
  github_document: 
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
library('skimr')
library('tree')
library('ggplot2')
library('corrplot')
library('ROCR')
library('randomForest')
library('gbm')
library('readxl')
```

# Introduction

### Data Set Information: 
This data set is a survey conducted in 2015 on Airline Passengers Satisfaction level where it contains other attributes such as Type of Travel, Gender, Airplane Amenities, Flight Distance and more. This data set was uploaded on Kaggle which can be found [here.](https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction)

### Goal:
To Answer 3 Research Questions:\
1. What are the statistically significant predictors for each of the machine learning models? \
2. What machine learning algorithm produced the highest accuracy in determining airline satisfaction level? \
3. How does each model handle imbalanced classes in the response variable?\

```{r cars}
# load the data
df = read_excel('~/Stat473/satisfaction_2015.xlsx')
glimpse(df)
```

# Exploratory Data Analysis 

```{r}
# Data Dimensions
dim(df)
```
We are given 24 features and 129,880 total observations for our dataset. 
```{r}
# Check for missing values
colSums(is.na(df))
```
\
As we can see our Arrival Delay in Minutes attribute has a total of 393 missing values. Since we are given a relatively large data set we will drop the observations with missing values. 
\
```{r}
# drop missing values
df = df |> drop_na()
# check for any missing values
sum(is.na(df))
```
```{r}
# check for duplicates
sum(duplicated(df))
```
```{r}
# statistical summary using skim function from skimr
skim(df)
```
```{r}
# convert categorical variables into factors
# drop the ID column
factor_names = c('satisfaction_v2', 'Gender', 'Customer Type', 'Type of Travel', 'Class' )
df = df |> dplyr::select(-1) |> 
  mutate_at(factor_names, as.factor)
```

```{r}
# renaming the columns to make it easier to work with

colnames(df) <- c('Satisfaction','Gender','CustomerType','Age', "TypeTravel", "Class", "FlightDistance", "InflightWifiService", "DepartArrive", "EaseOnlineBook", "GateLocation", "FoodDrink", "OnlineBoarding", "SeatComfort", "InFlightEntertainment", "OnBoardService", "LegRoomService", "BaggageHandling","CheckinService", "InflightService", "Cleanliness", "DepartureDelay", "ArrivalDelay" )
```

```{r}
# check column data types
str(df)
```

# Data Visualizations

```{r echo=TRUE}
# correlation matrix plot

# extract numeric columns only
numeric_cols <- sapply(df, is.numeric)
df_numeric <- df[, numeric_cols]

corr_matrix <- cor(df_numeric)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(corr_matrix, method = 'color', tl.cex = 0.5, title = "Correlation Matrix",
         mar=c(0,0,1,0))
```
\
From the Correlation matrix above we can see that Seat Comfort is high correlated with food/drinks, in flight entertainment, and cleanliness. We can also see On-board service is highly correlated with leg room service, baggage handling, in flight service, and in flight entertainment.
\
```{r echo=TRUE}
# bar chart on satisfaction
plot(df[,'Satisfaction'], main = 'Airline Satisfaction', 
     ylab = 'Count', xlab = 'Satisfaction Level', col = rainbow(2))
```
\
Satisfaction level is our response variable where we can clearly see it is a binary classification problem. Satisfaction level has 2 classes either satisfied or neutral/dissatisfied. From the bar chart above we can see that the classes are imbalanced. However, the imbalance is not too wide but we still have too consider that this may cause issues when fitting our models since they can learn a bit more on neutral/dissatisfied than the satisfied passengers.
\
```{r echo=TRUE}
# bar chart on Gender
plot(df[,'Gender'], main = 'Airline Genders', 
     ylab = 'Count', xlab = 'Gender', col = c('pink','lightblue'))
```
```{r echo=TRUE}
# bar chart on Airline Class
plot(df[,'Class'], main = 'Airline Class', 
     ylab = 'Count', xlab = 'Airline Class',  col = c("#E69F00", "#56B4E9", "#009E73"))
```
\
Here we can see from the Gender bar chart that we have an almost even distribution on Females and Males in our data set with a slightly bit more Females. From the Airline Class bar chart we can see that a majority of passengers in our data were buying Business and Economic fares over the Economic Plus fares. 
\
```{r echo=TRUE}
# bar chart on Airline Type of Travel
plot(df[,'TypeTravel'], main = 'Airline Travel Type', 
     ylab = 'Count', xlab = 'Travel Type', col = c("yellow", "#009E73"))
```
```{r echo=TRUE}
# bar chart on Airline Customer Type
plot(df[,'CustomerType'], main = 'Airline Customer Type', 
     ylab = 'Count', xlab = 'Customer Type', col = c("#56B4E9", "#009E73"))
```
\
Here we can see that a majority of the passengers collect in our data set were primarily traveling for business purposes rather than personal situations. Note this may include bias since majority of the passengers are in this data are traveling for business. Also we can see that a majority of the passengers in the data are loyal customers and we have a few disloyal or new customers. 
\
```{r echo=TRUE}
# Age histogram separated by Gender
ggplot(df, aes(x = Age, color = Gender, fill = Gender)) + 
  geom_histogram(bins = 30) + 
  labs(title = "Age Histogram Separated by Gender", x = "Age", y = "Count")
```
\
From the Age histogram above we can see that a majority of the passengers Age in our data range between 25 to 60 years old. Now if we separate the age histogram by gender we can see that we have more Females in all ranges of ages than Males. 
\
```{r echo=TRUE}
ggplot(df, aes(x = FlightDistance)) +                         
  geom_histogram(aes(y = after_stat(density)), bins = 40, fill = "lightblue") +
  geom_density(alpha = 0.1, fill = "lightgreen") +
  labs(title="Flight Distance Density Plot",x="Flight Distance")
```

\
Here we can see the majority of Flight Distances were no more than 1000 kilometers. 
\

# Modeling 

```{r include=FALSE}
# Metric Functions
confusion =  function(cm){
  TP = cm[1,1]
  FP = cm[1,2]
  FN = cm[2,1]
  TN = cm[2,2]
  list = list(TP,FP,FN,TN)
  return(list)
}

accuracy = function(cm){
  list = confusion(cm)
  return(((list[[1]]+list[[4]])/(list[[1]]+list[[2]]+list[[3]]+list[[4]])))
}

sensitivity = function(cm){
  list = confusion(cm)
  sense = list[[1]]/ (list[[1]]+list[[3]])
  return(sense)
}

specificity = function(cm){
  list = confusion(cm)
  return(list[[4]] / (list[[4]]+list[[2]]))
}
```

```{r}
# split the data
# split train and test sets to a 80/20 split
n = nrow(df)
prop = .80
set.seed(1)
train_id = sample(1:n, size = round(n*prop), replace = FALSE)
test_id = (1:n)[-which(1:n %in% train_id)]
train_set = df[train_id, ]
test_set = df[test_id, ]
```

## Logistic Regression

```{r}
# Fitting a Logistic Regression Model with all predictors
log.fit = glm(Satisfaction ~., data = train_set, family = 'binomial')
summary(log.fit)
```
\
Considering a Hypothesis test, where our null hypothesis is $H_0: \beta_i = 0$ versus our alternative hypothesis $H_a: \beta_i \neq 0$, where $i =$ all of the predictors used. We can see that the only predictor variable that fail to reject our null hypothesis when using a significance level of, $\alpha = 0.05$, is Flight Distance. Hence, the attribute Flight Distance is statistically insignificant to our Logistic Regression Model. We will fit another Logistic Regression model but with only the statistically significant predictors. 
\
```{r}
# Fitting a Logistic Regression Model with all significant predictors

log.fit2 = glm(Satisfaction ~ Gender + CustomerType + Age + TypeTravel + 
                 Class + InflightWifiService + DepartArrive + 
                 EaseOnlineBook + GateLocation + FoodDrink + 
                 OnlineBoarding + SeatComfort + InFlightEntertainment +
                 OnBoardService + LegRoomService + BaggageHandling + 
                 CheckinService + InflightService + Cleanliness + 
                 DepartureDelay + ArrivalDelay,
                 data = train_set, family = 'binomial')

summary(log.fit2)
```
```{r}
# log confusion matrix with significant predictors 
y_pred_log = predict(log.fit2, newdata = test_set, type = 'response')
y_pred_log = ifelse(y_pred_log > 0.5, 'satisfied', 'neutral/dissatisfied')
log_cm = table(predict_status = y_pred_log, true_status = test_set$Satisfaction)
print(log_cm)
cat('\nThe Accuracy is:', accuracy(log_cm))
cat('\nThe Sensitivity is:', sensitivity(log_cm))
cat('\nThe Specificity is:', specificity(log_cm))
```
\
The accuracy of the Logistic Regression model with only the significant predictors is 87.5\%. However, observing other metrics such as sensitivity and specificity we can see that the model had a higher sensitivity rate compared to the specificity rate. This is due to the imbalanced classes in our satisfaction response variable. Recall, we had more neutral/dissatisfied passengers in our data set, which explains why our sensitivity rate is greater. Our model learned the neutral/dissatisfied passengers better than satisfied passengers. If we want to accurately determine a satsified passeneger we might want to increase the specificity rate. 
\
```{r}
# Logistic Regression ROC Curve
y_pred_log = predict(log.fit2, newdata = test_set, type = 'response')
pred_log = prediction(y_pred_log, test_set$Satisfaction)
perf = performance(pred_log, "tpr", "fpr")
plot(perf, main = "Logistic Regression ROC Curve")
abline(0, 1, lty=3)
```
```{r}
# Logistic Regression AUC Value
log_auc = as.numeric(performance(pred_log, "auc")@y.values)
log_auc
```

## Random Forest 

```{r}
# Fitting a Random Forest with all predictors
p = ncol(train_set) - 1

set.seed(123)
forest.fit = randomForest(Satisfaction ~., data = train_set, mtry = round(sqrt(p)), importance = TRUE)
forest.fit
```
```{r}
# Random Forest Confusion Matrix
yhat.forest = predict(forest.fit, test_set, type = "class")
forest_cm = table(predict_status = yhat.forest, true_status = test_set$Satisfaction)
forest_cm
cat('\nThe Accuracy is:', accuracy(forest_cm))
cat('\nThe Sensitivity is:', sensitivity(forest_cm))
cat('\nThe Specificity is:', specificity(forest_cm))
```
\
Now the random forest model returned an accuracy of 96.52\% on the testing data, implying the model did a pretty good job. This is a pretty good accuracy since the model predicted on unseen data, testing set, implying our model did not over fit on the training data. This means our Random Forest has low variance and high bias which is the most optimal situation. Now, Random Forest handled the imbalanced classes in our response pretty good as well, this may be due to the splits on the several decision trees. 
\
```{r}
# Random Forest Feature Importance
varImpPlot(forest.fit, main = "Variable Importance (Random Forest)", type = 2)
```
\
We see that having the predictor Online Boarding on top of the trees had the overall greatest decrease in gini index. Hence, implying online Boarding is a significant predictor in the splitting of the nodes for our Random Forest model. 
\

## Boosting 

```{r}
# Encoding Our Satisfaction column 
df = df |> mutate(satisfaction_numeric = ifelse(Satisfaction == "satisfied",1,0)) |> dplyr::select(-Satisfaction)
```
```{r}
glimpse(df)
```
```{r}
# splitting our data into train/test with 80/20
n = nrow(df)
prop = .8
set.seed(123)
train_id = sample(1:n, size = round(n*prop), replace = FALSE)
test_id = (1:n)[-which(1:n %in% train_id)]

train_set = df[train_id, ]
test_set = df[test_id, ]
```
```{r}
# parameters we check
grid = expand.grid(
    n.trees_vec = c(200),
    shrinkage_vec = c(0.25, 0.30, 0.32),
    interaction.depth_vec = c(3),
    miss_classification_rate = NA,
    time = NA
)

head(grid, 10)
```
```{r}
# grid search for best parameters for our Boosting model
set.seed(1)
for(i in 1:nrow(grid)){
  time = system.time({
    boost_fit = gbm(satisfaction_numeric ~ ., train_set,
                      n.trees = grid$n.trees_vec[i],
                      shrinkage = grid$shrinkage_vec[i],
                      interaction.depth = grid$interaction.depth_vec[i],
                      distribution = "bernoulli", cv.folds = 5)
}
)
  grid$miss_classification_rate[i] =
    boost_fit$cv.error[which.min(boost_fit$cv.error)]
  grid$time[i] = time[["elapsed"]]
}
```

```{r}
# arranging the miss_classification_rate in ascending order
grid |> arrange(miss_classification_rate)
```
```{r}
# Our best Boosting model with lowest miss classification rate
boost.fit.best = gbm(satisfaction_numeric ~ ., train_set, n.trees = 200, 
                     shrinkage = 0.32, interaction.depth = 3,
                     distribution = "bernoulli")
boost.fit.best
```
```{r}
# Feature Importance
summary.gbm(boost.fit.best)
```
\
In our Boosting Model we can see that the predictors that had the most influence in terms of a passenger satisfaction was high dependent on Online Boarding, In Flight WiFi Service, Type of Travel, and Class.
\
```{r}
# Boosting Confusion Matrix
phat.test.boost.best = predict(boost.fit.best, test_set, type = "response")
yhat.test.boost.best = ifelse(phat.test.boost.best > 0.5, 1, 0)
boost_cm = table(pred = yhat.test.boost.best, true = test_set$satisfaction_numeric)
boost_cm
cat('\nThe Accuracy is:', accuracy(boost_cm))
cat('\nThe Sensitivity is:', sensitivity(boost_cm))
cat('\nThe Specificity is:', specificity(boost_cm))
```
\
Our boosting algorithm after doing a grid search for the most optimal parameters in terms of the miss-classification rate returned an accuracy of 95.37\%. Overall, the boosting model performed slightly under the Random Forest model which can be due to our parameter tuning. Since Boosting still uses trees to classify an observation this can also explain why it handled the imbalanced satisfaction classes pretty well. 
\
```{r}
Models = c('Logistic Regression', 'Random Forest', 'Boosting')
Accuracy = c(accuracy(log_cm), accuracy(forest_cm), accuracy(boost_cm))
Sensitivity = c(sensitivity(log_cm), sensitivity(forest_cm), sensitivity(boost_cm))
Specificity = c(specificity(log_cm), specificity(forest_cm), specificity(boost_cm))

Results = data.frame(Models,Accuracy,Sensitivity, Specificity)
Results
```

# Conclusion

In terms of accuracy the best model out of the three models trained was Random Forest which returned an 96\% accuracy on the testing set. While Logistic Regression had the lowest accuracy with a score of 87\% which is still relatively good since it was the score on unseen data. In terms of flexibility, Logistic Regression is the best for real world situations since we can play with the metrics and get the results we need. For Example, if an airline cared about correctly identifying a passenger who was satisfied with the flight we might want to change the threshold on the Logistic model to increase specificity rate to reduce the amount of error in identifying a satisfied passenger. Overall, Boosting was slightly behind Random Forest which could be due to a parameter tuning issue since we only checked a small subset of parameters for our model. 

## Business Insights

If an airline cared to increase satisfaction levels of passengers in their airline, we observed that Online Boarding, In Flight WiFi Service, Travel Type, Class, In Flight Entertainment, Leg Room Service, Customer Type, Check In Service, On Board Service, In Flight Service, Seat Comfort, and Departure Arrival Time. However, the attributes that we can control to increase satisfaction level for our airline in this specific order since the level of influence for each attribute is different is given:

1. Online Boarding - make it easier to purchase fares online and see flight information.
2. In Flight WiFi Service - provide WiFi services to all passengers, can include a premium service bundle that provides faster internet speeds and food/drinks for said customer. 
3. In Flight Entertainment - Perhaps suggest films, videos, or reading articles for passengers.
4. Leg Room Service - improve leg room in our seating.
5. Check In Service & On Board Service - provide excellent service to make them more welcome/comfortable.
6. In Flight Service - improve our in flight service. 

An improvement on a combination of features above can lead to greater satisfaction levels from our passengers. Satisfied customers can improve our airline brand and attract new customers to our fleet. 

































