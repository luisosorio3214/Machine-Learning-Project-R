---
title: "Microsoft Stock"
output: 
  github_document: default
  html_document: default
  pdf_document: default
date: "2023-04-25"
url: blue
---
by Luis Osorio

# Microsoft Stock - Price Prediction

## Data Info:
The Data was scraped from Yahoo Finance which you can find [here.](https://finance.yahoo.com/quote/MSFT/?fr=sycsrp_catchall). 

## Goal:
Which model from the two, Long Short Term Memory(LSTM) or Gated Recurrent Unit (GRU) performs best in predicting microsoft closing price?

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
library('readr')
Sys.setenv(RETICULATE_PYTHON = "/Users/luisosorio/Library/r-miniconda/envs/r-reticulate/bin/python")
library('reticulate')
repl_python()
```

```{r}
# load the data
msft.data <- read.csv(file = "~/Stat510/MSFT.csv", header = TRUE, sep = ",")

# print first 5 observations
head(msft.data,5)
```

```{r}
# splitting data into testing and training sets

# formatting the Date column 
msft.data$Year <- as.numeric(format(as.Date(msft.data$Date, format = "%Y-%m-%d"),"%Y"))

train.data <- msft.data[which(msft.data$Year < 2023), 1:5]
test.data <- msft.data[which(msft.data$Year >= 2023), 1:5]
```

```{r}
# plotting the closing price
plot(as.POSIXct(msft.data$Date), 
     msft.data$Close, 
     main = "Daily Microsoft Stock Closing Prices", 
     xlab = "Time", 
     ylab = "Stock Close Price", 
   col = 'orange',type = 'l', lwd = 2)
```

```{r}
# glimpse of the test data

glimpse(test.data)
```

```{r}
# plotting training and testing data
plot(as.POSIXct(msft.data$Date), 
     msft.data$Close, 
     main = "Daily Microsoft Stock Closing Prices", 
     xlab = "Time", 
     ylab = "Stock Close Price", 
     pch = "", 
     panel.first = grid())

lines(as.POSIXct(train.data$Date), train.data$Close, lwd = 2, col = "blue")
lines(as.POSIXct(test.data$Date), test.data$Close, lwd = 2, col = "green")
legend("topleft", c("training", "testing"), lty = 1, col = c("blue","green"))
```

```{r}
# scaling prices to fall in [0,1]
price <- msft.data$Close
price.sc <- (price - min(price))/(max(price) - min(price))
```

```{r}
# Preparing our train matrix for our models

nsteps <- 73 #width of sliding window
train.matrix <- matrix(nrow = nrow(train.data) - nsteps, ncol = nsteps + 1)
for (i in 1:(nrow(train.data) - nsteps))
  train.matrix[i,] <- price.sc[i:(i + nsteps)]

# creating train.x and train.y 
train.x <- array(train.matrix[,-ncol(train.matrix)],dim = c(nrow(train.matrix),nsteps,1))
train.y <- train.matrix[,ncol(train.matrix)]
```


```{r}
#creating test.x and test.y
test.matrix <- matrix(nrow = nrow(test.data), ncol = nsteps + 1)
for (i in 1:nrow(test.data)) 
  test.matrix[i,] <- price.sc[(i + nrow(train.matrix)):(i + nsteps + nrow(train.matrix))]

test.x <- array(test.matrix[,-ncol(test.matrix)],dim = c(nrow(test.matrix),nsteps,1))
test.y <- test.matrix[,ncol(test.matrix)]
```

```{r}
#################################################
# LSTM MODEL
##################################################
# loading machine learning libraries
library('tensorflow')
library('keras')

# use_condaenv("r-reticulate", required = TRUE)
```
```{r}
# setting our LSTM Model
LSTM.model <- keras_model_sequential() 

# specifying model structure
LSTM.model %>% layer_lstm(input_shape = dim(train.x)[2:3], units = nsteps)
LSTM.model %>% layer_dense(units = 1, activation = "tanh") 
LSTM.model %>% compile(loss = "mean_squared_error")
```

```{r}
# training model
epochs <- 5  
for (i in 1:epochs) {
  LSTM.model %>% fit(train.x, train.y, batch_size = 32, epochs = 1)
  LSTM.model %>% reset_states() #clears the hidden states in network after every batch
}
```

```{r}
# predicting for testing data
pred.y <- LSTM.model %>% predict(test.x, batch_size = 32)
```

```{r}
# rescaling test.y and pred.y back to the original scale
test.y.re <- test.y*(max(price) - min(price)) + min(price)
pred.y.re <- pred.y*(max(price) - min(price)) + min(price)
```

```{r}
#computing prediction accuracy
accuracy10 <- ifelse(abs(test.y.re - pred.y.re) < 0.10*test.y.re,1,0) 
accuracy15 <- ifelse(abs(test.y.re - pred.y.re) < 0.15*test.y.re,1,0) 
accuracy20 <- ifelse(abs(test.y.re - pred.y.re) < 0.20*test.y.re,1,0)
```

```{r}
print(paste("accuracy within 10%:", round(mean(accuracy10),4)))
print(paste("accuracy within 15%:", round(mean(accuracy15),4)))
print(paste("accuracy within 20%:", round(mean(accuracy20),4)))

# plotting actual and predicted values for testing data
plot(as.POSIXct(test.data$Date), test.y.re, type = "l", lwd = 2, col = "green", 
  main = "Daily Microsoft Stock Actual and Predicted Prices - LSTM Model", 
  xlab = "Time", ylab = "Stock Price", panel.first = grid())
  lines(as.POSIXct(test.data$Date), pred.y.re, lwd = 2, col = "orange")
  legend("topright", c("actual", "predicted"), lty = 1, lwd = 2,
  col = c("green","orange"))
```

```{r}
#################################################
# GRU MODEL
##################################################

# instantiate our model
GRU.model <- keras_model_sequential() 
```

```{r}
# specifying model structure
GRU.model %>% layer_gru(input_shape = dim(train.x)[2:3], units = nsteps)
GRU.model %>% layer_dense(units = 1, activation = "tanh") 
GRU.model %>% compile(loss = "mean_squared_error")
```

```{r}
# training model
epochs <- 5  
for (i in 1:epochs) {
  GRU.model %>% fit(train.x, train.y, batch_size = 32, epochs = 1)
  GRU.model %>% reset_states() 
}
```

```{r}
# predicting for testing data
pred.y <- GRU.model %>% predict(test.x, batch_size = 32)
```

```{r}
# rescaling pred.y back to the original scale
pred.y.re <- pred.y*(max(price) - min(price)) + min(price)
```

```{r}
#computing prediction accuracy
accuracy10 <- ifelse(abs(test.y.re - pred.y.re) < 0.10*test.y.re,1,0) 
accuracy15 <- ifelse(abs(test.y.re - pred.y.re) < 0.15*test.y.re,1,0) 
accuracy20 <- ifelse(abs(test.y.re - pred.y.re) < 0.20*test.y.re,1,0)
```

```{r}
print(paste("accuracy within 10%:", round(mean(accuracy10),4)))
print(paste("accuracy within 15%:", round(mean(accuracy15),4)))
print(paste("accuracy within 20%:", round(mean(accuracy20),4)))


#plotting actual and predicted values for testing data
plot(as.POSIXct(test.data$Date), test.y.re, type = "l", lwd = 2, col = "green", 
  main = "Daily Microsoft Stock Actual and Predicted Prices - GRU Model", 
  xlab = "Time", ylab = "Stock Price", panel.first = grid())
  lines(as.POSIXct(test.data$Date), pred.y.re, lwd = 2, col = "orange")
  legend("topright", c("actual", "predicted"), lty = 1, lwd = 2,
  col = c("green","orange"))
```


















